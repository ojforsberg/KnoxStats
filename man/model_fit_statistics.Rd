% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/modelFit.R
\name{model_fit_statistics}
\alias{model_fit_statistics}
\title{Model Fit Statistics}
\arguments{
\item{model}{A fitted statistical model object (e.g., from \code{lm()},
\code{glm()}) that has methods for \code{logLik()} and \code{nobs()}.}
}
\value{
A numeric value representing the information criterion for the model.
}
\description{
A collection of functions to calculate various information criteria for
statistical model selection. These criteria help balance model fit with
complexity to prevent overfitting.
}
\details{
Information criteria are tools for selecting among statistical models.
They all follow the same basic form: -2*log-likelihood + penalty for complexity.
The penalty term varies between criteria, with some being more conservative
(penalizing complex models more heavily) than others.

When comparing models using these criteria:
\itemize{
\item{Lower values indicate better models (better fit with less complexity)}
\item{Compare models fit to the same data}
\item{Differences > 2-4 are usually considered meaningful}
\item{No single criterion is always best - consider several}
}
}
\examples{
# Fit a simple linear regression model
data(mtcars)
model1 <- lm(mpg ~ wt, data = mtcars)
model2 <- lm(mpg ~ wt + hp, data = mtcars)

# Calculate AIC for both models
AIC2(model1)
AIC2(model2)

# Calculate SBC (BIC) - more conservative
SBC(model1)
SBC(model2)

# For small samples, use AICc
AICc(model1)

# Get all fit statistics at once
\dontrun{
model.fit(model1)
}

# Compare two models
\dontrun{
cat("Model 1 (mpg ~ wt):\n")
model.fit(model1)
cat("Model 2 (mpg ~ wt + hp):\n")
model.fit(model2)
}

}
\references{
Akaike, Hirotugu. 1974. "A New Look at the Statistical Model Identification."
\emph{IEEE Transactions on Automatic Control} 19 (6): 716–23.

Schwarz, Gideon. 1978. "Estimating the Dimension of a Model."
\emph{The Annals of Statistics} 6 (2): 461–64.

Burnham, Kenneth P., and David R. Anderson. 2002. \emph{Model Selection
and Multimodel Inference: A Practical Information-Theoretic Approach}.
2nd ed. New York: Springer.

Hurvich, Clifford M., and Chih-Ling Tsai. 1989. "Regression and Time Series
Model Selection in Small Samples." \emph{Biometrika} 76 (2): 297–307.
}
\seealso{
\code{\link{AIC}} for R's built-in AIC function,
\code{\link{BIC}} for R's built-in BIC function,
\code{\link{logLik}} for extracting log-likelihood values,
\code{\link{nobs}} for getting number of observations
}
