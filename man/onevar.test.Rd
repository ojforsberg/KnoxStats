% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/onevar.test.R
\name{onevar.test}
\alias{onevar.test}
\title{One-Sample Variance Test (Chi-Square Test)}
\usage{
onevar.test(
  x,
  s2 = 1,
  conf.level = 0.95,
  alternative = c("two.sided", "less", "greater")
)
}
\arguments{
\item{x}{A numeric vector of sample data. Missing values (\code{NA}) are not allowed.}

\item{s2}{The hypothesized population variance under the null hypothesis.
Default is 1. Must be a positive number.}

\item{conf.level}{The confidence level for the confidence interval.
Must be between 0 and 1. Default is 0.95 (95\% confidence).}

\item{alternative}{The direction of the alternative hypothesis. Must be one of:
\code{"two.sided"} (default, σ² ≠ s2), \code{"less"} (σ² < s2), or \code{"greater"} (σ² > s2).}
}
\value{
A list with class \code{"htest"} containing the following components:
\item{statistic}{The chi-square test statistic (X²)}
\item{parameter}{Degrees of freedom (n - 1)}
\item{p.value}{The p-value for the test}
\item{conf.int}{Confidence interval for the population variance}
\item{estimate}{Sample variance}
\item{null.value}{The hypothesized population variance}
\item{alternative}{Character string describing the alternative hypothesis}
\item{method}{Character string indicating the test performed}
\item{data.name}{Character string giving the name of the data}
}
\description{
Performs a hypothesis test for the variance of a single population using the
chi-square distribution. This test determines whether the population variance
is equal to a specified value, or whether it is less than or greater than that
value. It is particularly useful in quality control and when checking
assumptions for other statistical tests.
}
\details{
This function performs a chi-square test for a single population variance.
The test assumes that the sample comes from a normally distributed population.
The test statistic follows a chi-square distribution with \code{n - 1} degrees of
freedom, where \code{n} is the sample size.

The test statistic is calculated as:
X² = (n - 1) * s² / σ²
where s² is the sample variance and σ² is the hypothesized population variance.

Confidence intervals are constructed using the chi-square distribution:
• Lower bound = (n - 1) * s² / χ²(1 - α/2)
• Upper bound = (n - 1) * s² / χ²(α/2)
for two-sided tests, with appropriate adjustments for one-sided alternatives.
}
\section{Assumptions}{

\enumerate{
\item The sample is randomly selected from the population.
\item The population follows a normal distribution.
\item Observations are independent of each other.
}
}

\section{Warning}{

This test is very sensitive to violations of the normality assumption. If the data
are not normally distributed, the results will  be unreliable. Consider using
nonparametric alternatives or transformations if normality is questionable.
}

\examples{
# Example 1: Testing if variance equals a specific value
set.seed(123)
data <- rnorm(30, mean = 100, sd = 15)  # Normally distributed data

# Two-sided test (default)
result <- onevar.test(data, s2 = 225)  # Test if variance = 225 (sd = 15)
print(result)

# Example 2: One-sided test for smaller variance
# Test if variance is less than 250
result_less <- onevar.test(data, s2 = 250, alternative = "less")
print(result_less)

# Example 3: One-sided test for larger variance
# Test if variance is greater than 200
result_greater <- onevar.test(data, s2 = 200, alternative = "greater")
print(result_greater)

# Example 4: Using different confidence level
result_99 <- onevar.test(data, s2 = 225, conf.level = 0.99)
print(result_99)

# Example 5: Practical application - quality control
# Suppose a machine produces parts with length variance that should be 0.04
parts <- c(10.1, 9.9, 10.0, 10.2, 9.8, 10.1, 9.9, 10.0, 10.2, 9.8)
qc_test <- onevar.test(parts, s2 = 0.04)
print(qc_test)

}
\references{
Devore, Jay L. 2011. \emph{Probability and Statistics for Engineering and the Sciences}.
8th ed. Boston: Cengage Learning.

Moore, David S., George P. McCabe, and Bruce A. Craig. 2017. \emph{Introduction to the
Practice of Statistics}. 9th ed. New York: W. H. Freeman.

NIST/SEMATECH. 2012. \emph{e-Handbook of Statistical Methods}.
http://www.itl.nist.gov/div898/handbook/.
}
\seealso{
• \code{\link{var.test}} for comparing two variances
• \code{\link{t.test}} for testing population means
• \code{\link{shapiro.test}} for testing normality assumption
• \code{\link[KnoxStats]{fisherVar_test}} for the non-parametric alternative
}
